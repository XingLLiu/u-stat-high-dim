{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy.stats import norm\n",
    "import multiprocessing\n",
    "\n",
    "import tensorflow as tf\n",
    "import tensorflow_probability as tfp\n",
    "tfd = tfp.distributions\n",
    "\n",
    "import sys\n",
    "sys.path.append(\".\")\n",
    "from src.dc_smc import dc_smc \n",
    "from src.model import Model\n",
    "from src.utils import resample"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Linear Gaussian HMM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "#! matrix multiplication is wrong!\n",
    "class LinearGaussian:\n",
    "    def __init__(self, sigma0, A, B, C, D):\n",
    "        self.sigma0 = sigma0\n",
    "        self.mu0 = np.zeros((1, 1))\n",
    "        self.A = A\n",
    "        self.B = B\n",
    "        self.C = C\n",
    "        self.D = D\n",
    "    def sample(self, nsamples):\n",
    "        \"\"\"sample x_i for i=1:(n+1) and y_i for i=1:n\n",
    "        \"\"\"\n",
    "        x_vec = np.zeros((nsamples+1, 1))\n",
    "        y_vec = np.zeros((nsamples, 1))\n",
    "        \n",
    "        # sample x0 from prior\n",
    "        x_vec[0, :] = tfd.Normal(loc=self.mu0, scale=self.sigma0).sample(1)\n",
    "        # sample iteratively\n",
    "        for i in range(nsamples):\n",
    "            x_new, y_new = self.sample_once(x_vec[i, :], i)\n",
    "            x_vec[i+1, :] = x_new\n",
    "            y_vec[i, :] = y_new\n",
    "        \n",
    "        return x_vec, y_vec\n",
    "    \n",
    "    def update_sample(self, x_vec, y_vec, n=1):\n",
    "        \"\"\"sample n more data\n",
    "        \"\"\"\n",
    "        nsamples, dim = y_vec.shape\n",
    "        x_vec = np.append(x_vec, np.zeros((n, dim)), axis=0)\n",
    "        y_vec = np.append(y_vec, np.zeros((n, dim)), axis=0)\n",
    "        for i in range(n):\n",
    "            x_new, y_new = self.sample_once(x_vec[i+nsamples, :], i)\n",
    "            x_vec[i+1+nsamples, :] = x_new\n",
    "            y_vec[i+nsamples, :] = y_new\n",
    "        return x_vec, y_vec\n",
    "            \n",
    "    def sample_once(self, xt, t):\n",
    "        x_new = tf.math.multiply(self.A, xt) + \\\n",
    "            tf.math.multiply(self.B, tfd.Normal(loc=0, scale=1).sample(1)).numpy()\n",
    "        y_new = tf.math.multiply(self.C, x_new) + \\\n",
    "            tf.math.multiply(self.D, tfd.Normal(loc=0, scale=1).sample(1)).numpy()\n",
    "        return x_new, y_new\n",
    "            \n",
    "    def log_gamma(self, x_vec, y_vec):\n",
    "        \"\"\"unnormalized log posterior\n",
    "        \"\"\"\n",
    "        log_gamma = 0\n",
    "        nsamples = x_vec.shape[0]\n",
    "        \n",
    "        log_lik = tfd.MultivariateNormalFullCovariance(\n",
    "            loc=tf.math.multiply(self.C, x_vec[1:, :]), \n",
    "            covariance_matrix=self.D @ self.D.T\n",
    "        ).log_prob(y_vec)\n",
    "        \n",
    "        log_p = tfd.Normal(loc=self.mu0, scale=self.sigma0).log_prob(x_vec[0, :])\n",
    "        for i in range(1, nsamples):\n",
    "            log_p += tfd.MultivariateNormalFullCovariance(\n",
    "                loc=tf.math.multiply(self.A, x_vec[i-1, :]), \n",
    "                covariance_matrix=self.B @ self.B.T\n",
    "            ).log_prob(x_vec[i, :])\n",
    "        return log_p + tf.reduce_sum(log_lik)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[-0.35295168],\n",
       "        [-0.61807435],\n",
       "        [ 0.54944054],\n",
       "        [ 0.97703505],\n",
       "        [ 0.94505231],\n",
       "        [ 2.60163732]]),\n",
       " array([[0.20130504],\n",
       "        [0.77761779],\n",
       "        [1.16177938],\n",
       "        [1.11780159],\n",
       "        [3.4207777 ]]))"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sigma0 = np.array([[1.]])\n",
    "A = np.array([[0.8]])\n",
    "B = np.ones((1, 1))\n",
    "C = np.ones((1, 1))\n",
    "D = np.ones((1, 1))\n",
    "\n",
    "linear_hmm = LinearGaussian(sigma0, A, B, C, D)\n",
    "x_vec, y_vec = linear_hmm.sample(5)\n",
    "x_vec, y_vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[-0.35295168],\n",
       "        [-0.61807435],\n",
       "        [ 0.54944054],\n",
       "        [ 0.97703505],\n",
       "        [ 0.94505231],\n",
       "        [ 2.60163732],\n",
       "        [ 1.16896183]]),\n",
       " array([[0.20130504],\n",
       "        [0.77761779],\n",
       "        [1.16177938],\n",
       "        [1.11780159],\n",
       "        [3.4207777 ],\n",
       "        [1.37159199]]))"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "linear_hmm.update_sample(x_vec, y_vec, )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(1, 1), dtype=float64, numpy=array([[-13.36194099]])>"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "linear_hmm.log_gamma(x_vec, y_vec)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Non-linear Gaussian HMM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "#! matrix multiplication is wrong!\n",
    "class NonLinearGaussian(LinearGaussian):\n",
    "    def __init__(self, sigma0, sigma_v, sigma_w):\n",
    "        self.sigma0 = sigma0\n",
    "        self.mu0 = np.zeros((1, 1))\n",
    "        self.sigma_v = sigma_v\n",
    "        self.sigma_w = sigma_w\n",
    "            \n",
    "    def _latent_mean(self, xt, t):\n",
    "        return 0.5 * xt + 25 * xt / (1 + xt**2) + 8 * np.cos(1.2 * t)\n",
    "    \n",
    "    def sample_once(self, xt, t):\n",
    "        x_new = self._latent_mean(xt, t) + \\\n",
    "            tfd.Normal(loc=0, scale=self.sigma_v).sample(1).numpy()\n",
    "        y_new = 1/20 * x_new**2 + \\\n",
    "            tfd.Normal(loc=0, scale=self.sigma_w).sample(1).numpy()\n",
    "        return x_new, y_new\n",
    "            \n",
    "    def log_gamma(self, x_vec, y_vec):\n",
    "        \"\"\"unnormalized log posterior\n",
    "        \"\"\"\n",
    "        log_gamma = 0\n",
    "        nsamples = x_vec.shape[0]\n",
    "        \n",
    "        log_lik = tfd.Normal(\n",
    "            loc=1/20 * x_vec[1:, :]**2, \n",
    "            scale=self.sigma_w\n",
    "        ).log_prob(y_vec)\n",
    "\n",
    "        log_p = tfd.Normal(loc=self.mu0, scale=self.sigma0).log_prob(x_vec[0, :])\n",
    "        for i in range(1, nsamples):\n",
    "            log_p += tfd.Normal(\n",
    "                loc=self._latent_mean(x_vec[i-1, :], i), \n",
    "                scale=self.sigma_v\n",
    "            ).log_prob(x_vec[i, :])\n",
    "        return log_p + tf.reduce_sum(log_lik)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[ 0.90432218],\n",
       "        [26.43298512],\n",
       "        [18.74791913],\n",
       "        [ 0.58583726],\n",
       "        [ 2.45710654],\n",
       "        [ 8.00773997]]),\n",
       " array([[37.39417966],\n",
       "        [17.00759914],\n",
       "        [-1.21182593],\n",
       "        [ 0.79095997],\n",
       "        [ 4.98997146]]))"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sigma0 = np.array([[1.]])\n",
    "sigma_v = np.array([[np.sqrt(10)]])\n",
    "sigma_w = np.ones((1, 1))\n",
    "\n",
    "nonlinear_hmm = NonLinearGaussian(sigma0, sigma_v, sigma_w)\n",
    "x_vec2, y_vec2 = nonlinear_hmm.sample(5)\n",
    "x_vec2, y_vec2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[ 0.90432218],\n",
       "        [26.43298512],\n",
       "        [18.74791913],\n",
       "        [ 0.58583726],\n",
       "        [ 2.45710654],\n",
       "        [ 8.00773997],\n",
       "        [17.84976942]]),\n",
       " array([[37.39417966],\n",
       "        [17.00759914],\n",
       "        [-1.21182593],\n",
       "        [ 0.79095997],\n",
       "        [ 4.98997146],\n",
       "        [15.81851405]]))"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nonlinear_hmm.update_sample(x_vec2, y_vec2, )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5, 1)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(1, 1), dtype=float64, numpy=array([[-42.61334452]])>"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nonlinear_hmm.log_gamma(x_vec2, y_vec2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hierarchical model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hierarchical_targets(y, sigma0, eta, tau):\n",
    "    def log_gamma_leaf(x):\n",
    "        log_lik = tfd.Normal(loc=x, scale=eta).log_prob(y)\n",
    "        log_p = tfd.Normal(loc=mu0, scale=sigma0).log_prob(x[:, 0])\n",
    "        log_p += tfd.Normal(loc=x[:, 0], scale=tau).log_prob(x[:, 1:])\n",
    "        return log_p\n",
    "    \n",
    "    def sample_x(nsamples):\n",
    "        x_vec = np.zeros((nsapmles, 5))\n",
    "        x_vec[:, 0] = tfd.Normal(loc=mu0, scale=sigma0).sample(nsamples)\n",
    "        x_vec[:, 1:] = tfd.Normal(loc=x_vec[:, 0], scale=tau).sample((nsamples, x_vec.shape[1]-1))\n",
    "        return x_vec\n",
    "    \n",
    "    def sample(nsamples, x_vec):\n",
    "        y_vec = tfd.Normal(loc=x_vec[:, 1:], scale=eta).sample(nsamples)\n",
    "        return y_vec\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fast-mcmc",
   "language": "python",
   "name": "fast-mcmc"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
